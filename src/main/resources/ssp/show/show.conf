rdb {
  url = "jdbc:mysql://node17:3306/sight"
  user = "root"
  password = "root_root"
  kafka.offset.table = "offset"
  transaction.manager.table="sight.transaction_commited_table"
}
hive {
  jdbc.url = "jdbc:hive2://node17:10000/default"
}
message.client.url="http://node14:5555/"
kylin.client.url="http://node14:7070/kylin/api/"
kafka.producer {
  is.async=false
  set {
    bootstrap.servers="node30:6667,node31:6667,node32:6667"
    client.id="niubility_producer"
    acks=-1
    key.serializer="org.apache.kafka.common.serialization.StringSerializer"
    value.serializer="org.apache.kafka.common.serialization.StringSerializer"
  }
}
kafka.consumer {
  set {
    bootstrap.servers = "node30:6667,node31:6667,node32:6667"
    key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    auto.offset.reset = "earliest"
    #auto.offset.reset = "latest"
    enable.auto.commit = "false"
    request.timeout.ms = 2000
    session.timeout.ms = 1500
    heartbeat.interval.ms = 1000
  }
}
hbase {
  set {
    hbase.zookeeper.quorum = "node106,node107,node108"
    hbase.zookeeper.property.clientPort = "2181"
    spark.serializer = org.apache.spark.serializer.KryoSerializer
  }
}
spark.conf {
  app.name = "ssp_show"
//  streaming.batch.buration = 300
  streaming.batch.buration = 100
  set {
    mapreduce.job.queuename = queueA
    mapreduce.job.priority = HIGH
    hive.exec.dynamic.partition.mode = nonstrict
    spark.streaming.kafka.maxRatePerPartition = 20000
    #spark.streaming.kafka.maxRatePerPartition = 50000
    #spark.streaming.receiver.maxRate=1000
    spark.serializer = org.apache.spark.serializer.KryoSerializer
    spark.default.parallelism = 10
    hive.merge.mapfiles = true
    hive.merge.mapredfiles = true
    hive.merge.smallfiles.avgsize=1024000000
    spark.sql.shuffle.partitions = 3
    spark.kryoserializer.buffer.max=256
    //    spark.streaming.concurrentJobs = 3
  }
}
modules {

    show {
      class = "com.mobikok.ssp.data.streaming.module.MixModule"
      business.date.extract.by = "showTime"
      commit.time.interval = 1800
      commit.batch.size = 1
      dwi.enable = true
      dwi.table = "ssp_show_dwi"
      dwi.kafka.schema = "com.mobikok.ssp.data.streaming.schema.dwi.kafka.SspTrafficOldDWISchema"
      dwr.enable = true
      dwr.groupby.fields = [{
        expr = "publisherId", as = "publisherId"
      }, {
        expr = "subId",       as = "subId"
      }, {
        expr = "countryId",   as = "countryId"
      }, {
        expr = "carrierId",   as = "carrierId"
      }, {
        expr = "sv",          as = "sv"
      }, {
        expr = "adType",      as = "adType"
      }, {
        expr = "campaignId",  as = "campaignId"
      }, {
        expr = "offerId",     as = "offerId"
      }, {
        expr = "imageId",     as = "imageId"
      }, {
        expr = "affSub",      as = "affSub"
      }, {
        expr = "null",        as = "packageName"
      }, {
        expr = "null",        as = "domain"
      }, {
        expr = "null",        as = "operatingSystem"
      }, {
        expr = "null",        as = "systemLanguage"
      }, {
        expr = "null",        as = "deviceBrand"
      }, {
        expr = "null",        as = "deviceType"
      }, {
        expr = "null",        as = "browserKernel"
      }, {
        expr = "null",        as = "b_time"
      }]
      dwr.groupby.aggs = [{
        expr = "count(1)"
        as ="times"
        union = "sum(times)"
      }, {
        //1 cpc(click), 2 cpm(show), 3 cpa(转化数=计费数?)
        expr = "count( if( priceMethod = 2, 1, null) )"
        as ="cpmTimes"
        union = "sum(cpmTimes)"
      }, {
        //1 cpc(click), 2 cpm(show), 3 cpa(转化数=计费数?)
        expr = "sum( cast( if( priceMethod = 2,  bidPrice, 0) as decimal(19,10) ) ) / 1000"
        as ="cpmBidPrice"
        union = "sum(cpmBidPrice)"
      }, {
        //1 cpc(click), 2 cpm(show), 3 cpa(转化数=计费数?)
        expr = "sum( cast( if( priceMethod = 2,  sendPrice, 0) as decimal(19,10) ) )"
        as ="cpmSendPrice"
        union = "sum(cpmSendPrice)"
      }]
      dwr.include.repeated = true
      dwr.table = "ssp_show_dwr"
      dm.kafka.enable = true
      dm.kafka.topic = "topic_ssp_show_dwr"
      kafka.consumer {
        partitoins = [
          {
            topic = "topic_ad_show"
            partition = 0
          }
        ]
      }
    }
}