rdb {
  url = "jdbc:mysql://node17:3306/sight"
  user = "root"
  password = "root_root"
  kafka.offset.table = "offset"
  transaction.manager.table="sight.transaction_commited_table"
}
hive {
  jdbc.url = "jdbc:hive2://node17:10000/default"
}
message.client.url="http://node14:5555/"
kylin.client.url="http://node14:7070/kylin/api/"
kafka.producer {
  is.async=false
  set {
    bootstrap.servers="node30:6667,node32:6667"
    client.id="niubility_producer"
    acks=-1
    key.serializer="org.apache.kafka.common.serialization.StringSerializer"
    value.serializer="org.apache.kafka.common.serialization.StringSerializer"
  }
}
kafka.consumer {
  set {
    bootstrap.servers = "node30:6667,node31:6667,node32:6667"
    key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    //    auto.offset.reset = "earliest"
    auto.offset.reset = "latest"
    enable.auto.commit = "false"
    request.timeout.ms = 2000
    session.timeout.ms = 1500
    heartbeat.interval.ms = 1000
  }
}

hbase {
  set {
    hbase.zookeeper.quorum = "node106,node107,node108"
    hbase.zookeeper.property.clientPort = "2181"
    spark.serializer = org.apache.spark.serializer.KryoSerializer
  }
}
spark.conf {
  app.name = "sync"
  streaming.batch.buration = 90
  set {
    mapreduce.job.queuename = queueA
    mapreduce.job.priority = HIGH
    hive.exec.dynamic.partition.mode = nonstrict
//    spark.streaming.kafka.maxRatePerPartition = 1000
    spark.streaming.kafka.maxRatePerPartition = 1
    #spark.streaming.receiver.maxRate=1000
    spark.serializer = org.apache.spark.serializer.KryoSerializer
    spark.default.parallelism = 10
    hive.merge.mapfiles = true
    hive.merge.mapredfiles = true
    hive.merge.smallfiles.avgsize=1024000000
    spark.sql.shuffle.partitions = 3
    spark.kryoserializer.buffer.max=256
    spark.streaming.concurrentJobs = 1
  }
}
clickhouse {
  hosts = ["node111", "node110", "node16" , "node15"]
}
modules {

  // ===================================== day cost/showCount/clickCount ============================================
    sync_mysql_to_hive {
      class = "com.mobikok.ssp.data.streaming.module.PluggableModule"
      //取日期部分
      business.date.extract.by = "dwrBusinessDate"
      commit.batch.size = 0
      commit.time.interval = 0
      dwi.kafka.schema = "com.mobikok.ssp.data.streaming.schema.dwr.kafka.SspShowDWRSchema"

      fast.polling.enable=true
      dm.offline.handler.enable = true
      dm.offline.handlers = [{
        class = "com.mobikok.ssp.data.streaming.handler.dm.offline.SyncMysql2HiveHandlerV2"
        tables = [{
          mysql="ADVERTISER",hive="ADVERTISER",            uuid = "id"
        },
          {
            mysql="EMPLOYEE",hive="EMPLOYEE",                uuid = "id"
          },
          {
            mysql="EMPLOYEE",hive="ADVERTISER_AM",           uuid = "id"
          },
          {
            mysql="CAMPAIGN",hive="CAMPAIGN",                uuid = "id"
          },
          {
            mysql="OFFER",hive="OFFER",                      uuid = "id"
          },
          {
            mysql="PUBLISHER",hive="PUBLISHER",              uuid = "id"
          },
          {
            mysql="APP",hive="APP",                          uuid = "id"
          },
          {
            mysql="COUNTRY",hive="COUNTRY",                  uuid = "id"
          },
          {
            mysql="CARRIER",hive="CARRIER",                  uuid = "id"
          },
          {
            mysql="IMAGE_INFO",hive="IMAGE_INFO",            uuid = "id"
          },
          {
            mysql="VERSION_CONTROL",hive="VERSION_CONTROL",  uuid = "id"
          },
          {
            mysql="JAR_CONFIG",hive="JAR_CONFIG",            uuid = "id"
          },
          {
            mysql="JAR_CUSTOMER",hive="JAR_CUSTOMER",        uuid = "id"
          },
          {
            mysql="DSP_INFO",hive="DSP_INFO",                uuid = "id"
          },
          {
            mysql="IAB",hive="IAB"
          },
          {
            mysql="APP_AD",hive="APP_AD",                     uuid = "id"
          },
          {
            mysql="kok_ssp_stat.OFFER_DEMAND_CONFIG", hive="OFFER_DEMAND_CONFIG", uuid = "id"
          },
          {
            mysql="PROXY",hive="PROXY",                       uuid = "id"
          },
          {
            mysql="COMPANY",hive="COMPANY",                   uuid = "id"
          },
          {
            mysql="OTHER_SMART_LINK",hive="OTHER_SMART_LINK", uuid = "id"
          },
          {
            mysql="SMARTLINK_RULES",hive="SMARTLINK_RULES",   uuid = "id"
          }
        ]
        //        PRO
        //        rdb.url = "jdbc:mysql://104.250.131.130:8904/kok_ssp?rewriteBatchedStatements=true&autoReconnect=true&useUnicode=true&characterEncoding=utf8"
        rdb.url = "jdbc:mysql://192.168.111.12:8904/kok_ssp?autoReconnect=true&useUnicode=true&characterEncoding=UTF-8"
        rdb.user = "root"
        rdb.password = "@dfei$@DCcsYG"
      }]
      kafka.consumer {
        partitoins = [
          {
            topic = "topic_empty"
            partition = 0
          }
        ]
      }
    }
}